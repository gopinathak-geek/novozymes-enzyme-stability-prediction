{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e45bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Dataset, download_url, DataLoader\n",
    "from torch_geometric.loader import DataLoader\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8fe3449d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>seq_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "      <th>data_source</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AAAAKAAALALLGEAPEVVDIWLPAGWRQPFRVFRLERKGDGVLVG...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>75.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AAADGEPLHNEEERAGAGQVGRSLPQESEEQRTGSRPRRRRDLGSR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>50.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>AAAFSTPRATSYRILSSAGSGSTRADAPQVRRLHTTRDLLAKDYYA...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>40.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>AAASGLRTAIPAQPLRHLLQPAPRPCLRPFGLLSVRAGSARRSGLL...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>47.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>AAATKSGPRRQSQGASVRTFTPFYFLVEPVDTLSVRGSSVILNCSA...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>49.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26975</th>\n",
       "      <td>31385</td>\n",
       "      <td>31385</td>\n",
       "      <td>YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>51.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26976</th>\n",
       "      <td>31386</td>\n",
       "      <td>31386</td>\n",
       "      <td>YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26977</th>\n",
       "      <td>31387</td>\n",
       "      <td>31387</td>\n",
       "      <td>YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>64.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26978</th>\n",
       "      <td>31388</td>\n",
       "      <td>31388</td>\n",
       "      <td>YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26979</th>\n",
       "      <td>31389</td>\n",
       "      <td>31389</td>\n",
       "      <td>YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26980 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  seq_id                                   protein_sequence  \\\n",
       "0               0       0  AAAAKAAALALLGEAPEVVDIWLPAGWRQPFRVFRLERKGDGVLVG...   \n",
       "1               1       1  AAADGEPLHNEEERAGAGQVGRSLPQESEEQRTGSRPRRRRDLGSR...   \n",
       "2               2       2  AAAFSTPRATSYRILSSAGSGSTRADAPQVRRLHTTRDLLAKDYYA...   \n",
       "3               3       3  AAASGLRTAIPAQPLRHLLQPAPRPCLRPFGLLSVRAGSARRSGLL...   \n",
       "4               4       4  AAATKSGPRRQSQGASVRTFTPFYFLVEPVDTLSVRGSSVILNCSA...   \n",
       "...           ...     ...                                                ...   \n",
       "26975       31385   31385  YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...   \n",
       "26976       31386   31386  YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...   \n",
       "26977       31387   31387  YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...   \n",
       "26978       31388   31388  YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...   \n",
       "26979       31389   31389  YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...   \n",
       "\n",
       "        pH                        data_source    tm  \n",
       "0      7.0  doi.org/10.1038/s41592-020-0801-4  75.7  \n",
       "1      7.0  doi.org/10.1038/s41592-020-0801-4  50.5  \n",
       "2      7.0  doi.org/10.1038/s41592-020-0801-4  40.5  \n",
       "3      7.0  doi.org/10.1038/s41592-020-0801-4  47.2  \n",
       "4      7.0  doi.org/10.1038/s41592-020-0801-4  49.5  \n",
       "...    ...                                ...   ...  \n",
       "26975  7.0  doi.org/10.1038/s41592-020-0801-4  51.8  \n",
       "26976  7.0  doi.org/10.1038/s41592-020-0801-4  37.2  \n",
       "26977  7.0  doi.org/10.1038/s41592-020-0801-4  64.6  \n",
       "26978  7.0  doi.org/10.1038/s41592-020-0801-4  50.7  \n",
       "26979  7.0  doi.org/10.1038/s41592-020-0801-4  37.6  \n",
       "\n",
       "[26980 rows x 6 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv(\"data/raw/processed_training_data.csv\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "785e0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NovoDataset(Dataset):\n",
    "    def __init__(self, root, filename, test=False, transform=None, pre_transform=None):\n",
    "        self.test = test\n",
    "        self.filename = filename\n",
    "        super(NovoDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return self.filename\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        self.data = pd.read_csv(self.raw_paths[0]).reset_index()\n",
    "\n",
    "        if self.test:\n",
    "            return [f'data_test_{i}.pt' for i in list(self.data.index)]\n",
    "        else:\n",
    "            return [f'data_{i}.pt' for i in list(self.data.index)]\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        self.data = pd.read_csv(self.raw_paths[0])\n",
    "        for index, mol in tqdm(self.data.iterrows(), total=self.data.shape[0]):\n",
    "            mol_obj = Chem.MolFromSequence(mol[\"protein_sequence\"])\n",
    "            # Get node features\n",
    "            node_feats = self._get_node_features(mol_obj)\n",
    "            # Get edge features\n",
    "            edge_feats = self._get_edge_features(mol_obj)\n",
    "            # Get adjacency info\n",
    "            edge_index = self._get_adjacency_info(mol_obj)\n",
    "            # Get labels info\n",
    "            label = self._get_labels(mol[\"tm\"])\n",
    "\n",
    "            # Create data object\n",
    "            data = Data(x=node_feats, \n",
    "                        edge_index=edge_index,\n",
    "                        edge_attr=edge_feats,\n",
    "                        y=label                        \n",
    "                       ) \n",
    "            if self.test:\n",
    "                torch.save(data, \n",
    "                    osp.join(self.processed_dir, \n",
    "                                 f'data_test_{index}.pt'))\n",
    "            else:\n",
    "                torch.save(data, \n",
    "                    osp.join(self.processed_dir, \n",
    "                                 f'data_{index}.pt'))\n",
    "        \n",
    "    def _get_node_features(self, mol):\n",
    "        \"\"\" \n",
    "        This will return a matrix / 2d array of the shape\n",
    "        [Number of Nodes, Node Feature size]\n",
    "        \"\"\"\n",
    "        all_node_feats = []\n",
    "\n",
    "        for atom in mol.GetAtoms():\n",
    "            node_feats = []\n",
    "            # Feature 1: Atomic number        \n",
    "            node_feats.append(atom.GetAtomicNum())\n",
    "            # Feature 2: Atom degree\n",
    "            node_feats.append(atom.GetDegree())\n",
    "            # Feature 3: Formal charge\n",
    "            node_feats.append(atom.GetFormalCharge())\n",
    "            # Feature 4: Hybridization\n",
    "            node_feats.append(atom.GetHybridization())\n",
    "            # Feature 5: Aromaticity\n",
    "            node_feats.append(atom.GetIsAromatic())\n",
    "            # Feature 6: Total Num Hs\n",
    "            node_feats.append(atom.GetTotalNumHs())\n",
    "            # Feature 7: Radical Electrons\n",
    "            node_feats.append(atom.GetNumRadicalElectrons())\n",
    "            # Feature 8: In Ring\n",
    "            node_feats.append(atom.IsInRing())\n",
    "            # Feature 9: Chirality\n",
    "            node_feats.append(atom.GetChiralTag())\n",
    "\n",
    "            # Append node features to matrix\n",
    "            all_node_feats.append(node_feats)\n",
    "\n",
    "        all_node_feats = np.asarray(all_node_feats)\n",
    "        return torch.tensor(all_node_feats, dtype=torch.float)\n",
    "\n",
    "    def _get_edge_features(self, mol):\n",
    "        \"\"\" \n",
    "        This will return a matrix / 2d array of the shape\n",
    "        [Number of edges, Edge Feature size]\n",
    "        \"\"\"\n",
    "        all_edge_feats = []\n",
    "\n",
    "        for bond in mol.GetBonds():\n",
    "            edge_feats = []\n",
    "            # Feature 1: Bond type (as double)\n",
    "            edge_feats.append(bond.GetBondTypeAsDouble())\n",
    "            # Feature 2: Rings\n",
    "            edge_feats.append(bond.IsInRing())\n",
    "            # Append node features to matrix (twice, per direction)\n",
    "            all_edge_feats += [edge_feats, edge_feats]\n",
    "\n",
    "        all_edge_feats = np.asarray(all_edge_feats)\n",
    "        return torch.tensor(all_edge_feats, dtype=torch.float)\n",
    "\n",
    "    def _get_adjacency_info(self, mol):\n",
    "        \"\"\"\n",
    "        We could also use rdmolops.GetAdjacencyMatrix(mol)\n",
    "        but we want to be sure that the order of the indices\n",
    "        matches the order of the edge features\n",
    "        \"\"\"\n",
    "        edge_indices = []\n",
    "        for bond in mol.GetBonds():\n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "            edge_indices += [[i, j], [j, i]]\n",
    "\n",
    "        edge_indices = torch.tensor(edge_indices)\n",
    "        edge_indices = edge_indices.t().to(torch.long).view(2, -1)\n",
    "        return edge_indices\n",
    "\n",
    "    def _get_labels(self, label):\n",
    "        label = np.asarray([label])\n",
    "        return torch.tensor(label, dtype=torch.int64)\n",
    "    \n",
    "    def len(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def get(self, idx):\n",
    "        \"\"\" - Equivalent to __getitem__ in pytorch\n",
    "            - Is not needed for PyG's InMemoryDataset\n",
    "        \"\"\"\n",
    "        if self.test:\n",
    "            data = torch.load(osp.join(self.processed_dir, \n",
    "                                 f'data_test_{idx}.pt'))\n",
    "        else:\n",
    "            data = torch.load(osp.join(self.processed_dir, \n",
    "                                 f'data_{idx}.pt'))   \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d33c3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NovoDataset(root=\"data/\", filename=\"processed_training_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6602fefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2557, 9], edge_index=[2, 5202], edge_attr=[5202, 2], y=[1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ba7a82f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.6 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "training_data, validation_data = torch.utils.data.random_split(train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bd39d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch_geometric.nn import GCNConv, TopKPooling, global_mean_pool\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7e0bedcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (initial_conv): GCNConv(9, 64)\n",
      "  (conv1): GCNConv(64, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (conv3): GCNConv(64, 64)\n",
      "  (out): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Number of parameters:  13249\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 64\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        # Init parent\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        # GCN layers\n",
    "        self.initial_conv = GCNConv(9, embedding_size)\n",
    "        self.conv1 = GCNConv(embedding_size, embedding_size)\n",
    "        self.conv2 = GCNConv(embedding_size, embedding_size)\n",
    "        self.conv3 = GCNConv(embedding_size, embedding_size)\n",
    "\n",
    "        # Output layer\n",
    "        self.out = Linear(embedding_size*2, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch_index):\n",
    "        # First Conv layer\n",
    "        hidden = self.initial_conv(x, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "\n",
    "        # Other Conv layers\n",
    "        hidden = self.conv1(hidden, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "        hidden = self.conv2(hidden, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "        hidden = self.conv3(hidden, edge_index)\n",
    "        hidden = F.tanh(hidden)\n",
    "          \n",
    "        # Global Pooling (stack different aggregations)\n",
    "        hidden = torch.cat([gmp(hidden, batch_index), \n",
    "                            gap(hidden, batch_index)], dim=1)\n",
    "\n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.out(hidden)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "model = GCN()\n",
    "print(model)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d6d1442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCHSIZE = 64\n",
    "EPOCHS = 10\n",
    "criterion = nn.MSELoss()\n",
    "LEARNING_RATE = 0.001\n",
    "model.to(DEVICE)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "578dddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=training_data, batch_size=BATCHSIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "valid_loader = DataLoader(dataset=validation_data, batch_size=BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21b5904",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "32fd7eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/gopinath/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/gopinath/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'NovoDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m training_score \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m training_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     10\u001b[0m     batch\u001b[38;5;241m.\u001b[39mto(DEVICE)  \n\u001b[1;32m     12\u001b[0m   \u001b[38;5;66;03m#==========Forward pass===============\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:444\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:390\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1077\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1070\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1077\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel \u001b[38;5;241m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_score_history = []\n",
    "training_losses_history = []\n",
    "validation_score_history = []\n",
    "validation_losses_history = []\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    training_score = []\n",
    "    training_loss = []\n",
    "    for batch in train_loader:\n",
    "        batch.to(DEVICE)  \n",
    "    \n",
    "      #==========Forward pass===============\n",
    "        pred, embedding = model(batch.x.float(), batch.edge_index, batch.batch)\n",
    "        loss = criterion(pred, batch.y)\n",
    "      #==========backward pass==============\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        train_result = stats.spearmanr(pred.detach().cpu().numpy(), batch.y.cpu().numpy())\n",
    "        training_score.append(train_result.correlation)\n",
    "        training_loss.append(loss.item())\n",
    "    \n",
    "    validation_score = []\n",
    "    validation_loss = []\n",
    "    for batch in valid_loader:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            batch.to(DEVICE)\n",
    "            \n",
    "            val_preds, val_embedding = model(batch.x.float(), batch.edge_index, batch.batch)\n",
    "            val_loss = criterion(val_preds, batch.y)\n",
    "\n",
    "            val_result = stats.spearmanr(val_preds.detach().cpu().numpy(), batch.y.cpu().numpy())\n",
    "            validation_score.append(val_result.correlation)\n",
    "            validation_loss.append(val_loss.item())\n",
    "        training_scores = np.mean(training_score)\n",
    "        training_losses = np.mean(training_loss)\n",
    "        validation_scores = np.mean(validation_score)\n",
    "        validation_losses = np.mean(validation_loss)\n",
    "\n",
    "        training_score_history.append(training_scores)\n",
    "        training_losses_history.append(training_losses)\n",
    "        validation_score_history.append(validation_scores)\n",
    "        validation_losses_history.append(validation_losses)\n",
    "        print(f'{epoch+1:03} EPOCH - Training score : {np.mean(training_scores):.5f} | Validation score : {np.mean(validation_scores):.5f} | Training loss : {np.mean(training_losses):.5f} | Validation loss : {np.mean(validation_losses):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393d6c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
